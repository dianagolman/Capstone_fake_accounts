{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9aff3530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "import pickle\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import sklearn.model_selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3166077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64243 entries, 0 to 64242\n",
      "Data columns (total 25 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Unnamed: 0       64243 non-null  int64  \n",
      " 1   Unnamed: 0.1     64243 non-null  int64  \n",
      " 2   posts            64243 non-null  int64  \n",
      " 3   flw              64243 non-null  int64  \n",
      " 4   flg              64243 non-null  int64  \n",
      " 5   pic              64243 non-null  int64  \n",
      " 6   link             64243 non-null  int64  \n",
      " 7   caption_len_avg  64243 non-null  int64  \n",
      " 8   cap_zero_per     64243 non-null  float64\n",
      " 9   no_image_per     64243 non-null  float64\n",
      " 10  likes_rate       64243 non-null  float64\n",
      " 11  comment_rate     64243 non-null  float64\n",
      " 12  loc_tag          64243 non-null  float64\n",
      " 13  hash_count       64243 non-null  float64\n",
      " 14  cosine_sim_avg   64243 non-null  float64\n",
      " 15  post_interval    64243 non-null  float64\n",
      " 16  class            64243 non-null  object \n",
      " 17  posts_a          64243 non-null  float64\n",
      " 18  flw_a            64243 non-null  float64\n",
      " 19  flg_a            64243 non-null  float64\n",
      " 20  likes_a          64243 non-null  float64\n",
      " 21  hash_a           64243 non-null  float64\n",
      " 22  cap_avg_a        64243 non-null  float64\n",
      " 23  comment_r_a      64243 non-null  float64\n",
      " 24  post_interval_a  64243 non-null  float64\n",
      "dtypes: float64(16), int64(8), object(1)\n",
      "memory usage: 12.3+ MB\n"
     ]
    }
   ],
   "source": [
    "account_t=pd.read_csv('../accounts_data_trim.csv')\n",
    "account_t.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ada8e3e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'posts', 'flw', 'flg', 'pic', 'link',\n",
       "       'caption_len_avg', 'cap_zero_per', 'no_image_per', 'likes_rate',\n",
       "       'comment_rate', 'loc_tag', 'hash_count', 'cosine_sim_avg',\n",
       "       'post_interval', 'class', 'posts_a', 'flw_a', 'flg_a', 'likes_a',\n",
       "       'hash_a', 'cap_avg_a', 'comment_r_a', 'post_interval_a'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "account_t.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5f62d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap_zero_per</th>\n",
       "      <th>no_image_per</th>\n",
       "      <th>loc_tag</th>\n",
       "      <th>class</th>\n",
       "      <th>posts_a</th>\n",
       "      <th>flw_a</th>\n",
       "      <th>flg_a</th>\n",
       "      <th>likes_a</th>\n",
       "      <th>hash_a</th>\n",
       "      <th>cap_avg_a</th>\n",
       "      <th>comment_r_a</th>\n",
       "      <th>post_interval_a</th>\n",
       "      <th>pic</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>f</td>\n",
       "      <td>44.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.094985</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>f</td>\n",
       "      <td>10.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>14.39</td>\n",
       "      <td>1.5</td>\n",
       "      <td>213.0</td>\n",
       "      <td>1.97</td>\n",
       "      <td>230.412857</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>f</td>\n",
       "      <td>33.0</td>\n",
       "      <td>970.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>10.10</td>\n",
       "      <td>2.5</td>\n",
       "      <td>436.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>43.569939</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>f</td>\n",
       "      <td>70.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>5.859799</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.667</td>\n",
       "      <td>f</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>14.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.126019</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cap_zero_per  no_image_per  loc_tag class  posts_a  flw_a  flg_a  likes_a  \\\n",
       "0           0.0           0.0    0.000     f     44.0   48.0  325.0     0.00   \n",
       "1           0.0           1.0    0.000     f     10.0   66.0  321.0    14.39   \n",
       "2           0.0           1.0    0.000     f     33.0  970.0  308.0    10.10   \n",
       "3           1.0           0.0    0.000     f     70.0   86.0  360.0     0.78   \n",
       "4           0.0           0.0    0.667     f      3.0   21.0  285.0    14.29   \n",
       "\n",
       "   hash_a  cap_avg_a  comment_r_a  post_interval_a  pic  link  \n",
       "0     0.0       12.0         0.00         0.094985    1     0  \n",
       "1     1.5      213.0         1.97       230.412857    1     0  \n",
       "2     2.5      436.0         0.30        43.569939    1     1  \n",
       "3     0.0        0.0         0.06         5.859799    1     0  \n",
       "4     0.0       93.0         0.00         0.126019    1     0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create dummy or indicator features from categorical features\n",
    "#Split into testing and training datasets \n",
    "\n",
    "#dfo=account_t.select_dtypes(include=['object']) # to select object type columns\n",
    "dfo=account_t[['pic','link']] # all data was numeric \n",
    "df_droped=account_t.drop(['Unnamed: 0', 'Unnamed: 0.1','pic','link', 'posts', 'flw', 'flg', 'likes_rate','hash_count', 'caption_len_avg', 'comment_rate', 'post_interval','cosine_sim_avg' ], axis=1)\n",
    "df = pd.concat([df_droped, pd.get_dummies(dfo)], axis=1)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ef48bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cap_zero_per       False\n",
       "no_image_per       False\n",
       "loc_tag            False\n",
       "class              False\n",
       "posts_a            False\n",
       "flw_a              False\n",
       "flg_a              False\n",
       "likes_a            False\n",
       "hash_a             False\n",
       "cap_avg_a          False\n",
       "comment_r_a        False\n",
       "post_interval_a    False\n",
       "pic                False\n",
       "link               False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing data again\n",
    "df.isnull().any()\n",
    "#if there are missing values we'll use to fill in any missing values\n",
    "#X_d_median = X_train.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2f71441b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset\n",
    "X=df.drop(['class'], axis=1)\n",
    "y=df['class'].map({'f':1,'r':0 })\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddf9297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the magnitude of numeric features using a scaler- since some of the features are percintage 0 to 1 \n",
    "#and some are big numbers. \n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_s=scaler.transform(X_train)\n",
    "X_test_s=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d832ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1- My categorical features were coded as int data type, is it good for the model?\n",
    "            # do we need them to be int or object for the model to work (\"correctly understanding the data\")\n",
    "# Question 2- There is no need to scale the categorical or the dummy variables but is it a mistake \n",
    "              #to transform the two i have (0/1) in the scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8303332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_= [0.001,0.01,0.1,1,10,100]\n",
    "accuracy=[]\n",
    "precision=[]\n",
    "\n",
    "for i in c_:\n",
    "\n",
    "    Log_r = LogisticRegression( C = i ,random_state = 42)\n",
    "    Log_r.fit(X_train_s, y_train)\n",
    "    \n",
    "    # Predict using model\n",
    "    y_pred = Log_r.predict(X_test_s)\n",
    "    ac=accuracy_score(y_test, y_pred)\n",
    "    accuracy.append(ac)\n",
    "    pr=precision_score(y_test, y_pred)\n",
    "    precision.append(pr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba5cd08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.807456</td>\n",
       "      <td>0.807061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.808779</td>\n",
       "      <td>0.808052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.808857</td>\n",
       "      <td>0.808082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.809168</td>\n",
       "      <td>0.808491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.809168</td>\n",
       "      <td>0.808491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.809168</td>\n",
       "      <td>0.808491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        c_  accuracy  precision\n",
       "0    0.001  0.807456   0.807061\n",
       "1    0.010  0.808779   0.808052\n",
       "2    0.100  0.808857   0.808082\n",
       "3    1.000  0.809168   0.808491\n",
       "4   10.000  0.809168   0.808491\n",
       "5  100.000  0.809168   0.808491"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores={\"c_\": c_, 'accuracy':accuracy, \"precision\":precision}\n",
    "scores=pd.DataFrame(scores)\n",
    "scores\n",
    "#0ne is the best c hyperparameter.\n",
    "# Precition score is important in this case as we want to detect the True positive and minimaize the false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff002a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81726036 0.80052646 0.81409121 0.8015778  0.80461256]\n",
      "cv mean train score 0.8051796406567366\n",
      "cv mean test score 0.8076136784568092\n",
      "[0.81710955 0.80035208 0.81400226 0.80155594 0.80458467]\n",
      "cv mean train score 0.8051605995077722\n",
      "cv mean test score 0.8075208990306818\n",
      "[0.88713543 0.86394999 0.8794774  0.86983961 0.87478787]\n",
      "cv mean train score 0.8751093221517813\n",
      "cv mean test score 0.8750380603861618\n"
     ]
    }
   ],
   "source": [
    "# Now I will use the model with hyperparameter c=1 and cross validate my sample.\n",
    "from sklearn.model_selection import cross_val_score\n",
    "Log_r = LogisticRegression( C = 1 ,random_state = 42)\n",
    "Log_r.fit(X_train_s, y_train)\n",
    "scoring=['precision_macro','f1_macro','roc_auc']\n",
    "for scor in scoring:\n",
    "    cv_scores_train= cross_val_score(Log_r ,X_train_s,y_train,cv=5,scoring=scor)\n",
    "    cv_scores_test= cross_val_score(Log_r,X_test_s, y_test,cv=5,scoring=scor)\n",
    "    cv_scores_log_test= cv_scores_test.mean()\n",
    "    cv_scores_log_train= cv_scores_train.mean()\n",
    "    print(cv_scores_test)\n",
    "    print(\"cv mean train score\", cv_scores_log_train)\n",
    "    print(\"cv mean test score\", cv_scores_log_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a93c3673",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import confusion_matrix\n",
    "#from sklearn.metrics import f1_score\n",
    "#Log_r.fit(X_train_s, y_train)\n",
    "#cnf_matrix= confusion_matrix(y_test,y_pred, normalize='true')\n",
    "#print(cnf_matrix)\n",
    "#pr_1=precision_score(y_test, y_pred)\n",
    "#f1_1=f1_score(y_test, y_pred)\n",
    "#print(pr_1, f1_1)\n",
    "# Precition score is important in this case as we want to detect the True positive and minimaize the false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dbfe58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next I will try the K nearest neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc8a0367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best leaf_size: 10\n",
      "Best p: 1\n",
      "Best n_neighbors: 9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#List Hyperparameters that we want to tune:\n",
    "leaf_size = list(range(1,50))\n",
    "n_neighbors = list(range(1,10))\n",
    "p=[1,2]\n",
    "\n",
    "hyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "#Use GridSearch\n",
    "clf = RandomizedSearchCV(knn, hyperparameters, cv=10)\n",
    "best_model = clf.fit(X_train_s, y_train)\n",
    "\n",
    "#Print The value of best Hyperparameters\n",
    "print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
    "print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
    "print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6fc4e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5893  551]\n",
      " [1326 5079]]\n",
      "0.9021314387211368\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "knn = KNeighborsClassifier(p=1, leaf_size=10 ,n_neighbors=9)\n",
    "knn.fit(X_train_s,y_train)\n",
    "\n",
    "# Predict using model:\n",
    "\n",
    "y_pred_knn=knn.predict(X_test_s)\n",
    "\n",
    "#Confusion matrix:\n",
    "\n",
    "matrix = confusion_matrix(y_test, y_pred_knn)\n",
    "print(matrix)\n",
    "pr_knn=precision_score(y_test, y_pred_knn)\n",
    "print(pr_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f8e5677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8537341709587336\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86      6444\n",
      "           1       0.90      0.79      0.84      6405\n",
      "\n",
      "    accuracy                           0.85     12849\n",
      "   macro avg       0.86      0.85      0.85     12849\n",
      "weighted avg       0.86      0.85      0.85     12849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "print(roc_auc_score(y_test, y_pred_knn))\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# This provides a lower ROC_AUC score, but better accuracy and precition. Which is a better model for our goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bafe435a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85574407 0.84599786 0.84590252 0.86544197 0.84672213]\n",
      "Mean cross validation test score: 0.851961712317042\n",
      "Mean cross validation train score: 0.8561709186229679\n",
      "Standard deviation in cv test scores: 0.007691009539526452\n"
     ]
    }
   ],
   "source": [
    "cv_scores_train= cross_val_score(knn,X_train_s,y_train,cv=5,scoring='precision_macro')\n",
    "cv_scores_test= cross_val_score(knn,X_test_s,y_test,cv=5,scoring='precision_macro')\n",
    "print(cv_scores_test)\n",
    "cv_scores_knn_test= cv_scores_test.mean()\n",
    "cv_scores_knn_train= cv_scores_train.mean()\n",
    "cv_scores_std_knn= cv_scores_test.std()\n",
    "print ('Mean cross validation test score: ' +str(cv_scores_knn_test))\n",
    "print ('Mean cross validation train score: ' +str(cv_scores_knn_train))\n",
    "print ('Standard deviation in cv test scores: ' +str(cv_scores_std_knn))\n",
    "# After cross validation the prediction score wasn't as high as in the initial sample, \n",
    "# but still higher than in logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "747bf015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "792ce02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6188  256]\n",
      " [1118 5287]] 0.8928609951780573 0.9538156233086776\n"
     ]
    }
   ],
   "source": [
    "#RF no max depth :\n",
    "Rf = RandomForestClassifier(bootstrap=True)\n",
    "Rf.fit(X_train_s, y_train)\n",
    "    #Predict using the model:\n",
    "y_predict_Rf = Rf.predict(X_test_s)\n",
    "    #Confusion matrix:\n",
    "c_matrix = confusion_matrix(y_test, y_predict_Rf)\n",
    "ra_a=roc_auc_score(y_test, y_predict_Rf)\n",
    "precision_3=precision_score(y_test, y_predict_Rf)\n",
    "print(c_matrix)\n",
    "print(\"roc_auc \"+ str(ra_a))\n",
    "print(\"precision \"+str(precision_3)\n",
    "\n",
    "# This model is overfitting and I will try some parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3bbbbfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc=[]\n",
    "precitions=[]\n",
    "max_d=[2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]\n",
    "for max_depth in range(2,20):\n",
    "    rf = RandomForestClassifier(bootstrap=True, max_depth=max_depth)\n",
    "    rf.fit(X_train_s, y_train)\n",
    "    #Predict using the model:\n",
    "    y_predict_rf = rf.predict(X_test_s)\n",
    "    #Confusion matrix:\n",
    "    cnf_matrix = confusion_matrix(y_test, y_predict_rf)\n",
    "    ra=roc_auc_score(y_test, y_predict_rf)\n",
    "    pr_3=precision_score(y_test, y_predict_rf)\n",
    "    roc_auc.append(ra)\n",
    "    precitions.append(pr_3)\n",
    "    #print(roc_auc_score(y_test, y_predict_rf))\n",
    "    #print(classification_report(y_test, y_predict_rf)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e85c8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    max_depth   roc_auc  precision\n",
      "0           2  0.855777   0.950732\n",
      "1           3  0.858160   0.936097\n",
      "2           4  0.874567   0.961872\n",
      "3           5  0.875493   0.966079\n",
      "4           6  0.877443   0.966783\n",
      "5           7  0.879385   0.970378\n",
      "6           8  0.883046   0.973735\n",
      "7           9  0.884531   0.973103\n",
      "8          10  0.886020   0.971037\n",
      "9          11  0.888521   0.970144\n",
      "10         12  0.889930   0.968832\n",
      "11         13  0.890792   0.967844\n",
      "12         14  0.891266   0.965793\n",
      "13         15  0.892838   0.961983\n",
      "14         16  0.894013   0.960738\n",
      "15         17  0.892379   0.958569\n",
      "16         18  0.892931   0.956459\n",
      "17         19  0.891843   0.954859\n",
      "best precition 0.973735032831209   best roc_auc 0.8940125847328888\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scores_rf={\"max_depth\": max_d, 'roc_auc':roc_auc, \"precision\":precitions}\n",
    "scores_=pd.DataFrame(scores_rf)\n",
    "print(scores_)\n",
    "scores_best_md = max(precitions)\n",
    "best_roc=max(roc_auc)\n",
    "print(\"best precition \" +str( scores_best_md), \"  best roc_auc \"+ str(best_roc))\n",
    "\n",
    "#The roc_auc reconds 6 trees, the precition 14 with higher score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7fd452c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89      6444\n",
      "           1       0.97      0.78      0.86      6405\n",
      "\n",
      "    accuracy                           0.88     12849\n",
      "   macro avg       0.89      0.88      0.88     12849\n",
      "weighted avg       0.89      0.88      0.88     12849\n",
      "\n",
      "[[6286  158]\n",
      " [1411 4994]]\n",
      "0.8775922122061879\n"
     ]
    }
   ],
   "source": [
    "#I will try the best max_depth with 6 and take aloot at the classification report:\n",
    "rf_1 = RandomForestClassifier(max_depth=6)\n",
    "rf_1.fit(X_train_s, y_train)\n",
    "#Predict using the model:\n",
    "\n",
    "y_predict_rf1 = rf_1.predict(X_test_s)\n",
    "#Confusion matrix:\n",
    "cnf_matrix_1 = confusion_matrix(y_test, y_predict_rf1)\n",
    "ra_1=roc_auc_score(y_test, y_predict_rf1)\n",
    "print(classification_report(y_test, y_predict_rf1))\n",
    "print(cnf_matrix_1)\n",
    "print(ra_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98dac2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88829634 0.89977496 0.88345903 0.89410592 0.88342732 0.88956149\n",
      " 0.89957632 0.88937472 0.89548182 0.88706115]\n",
      "Mean cross validation test score: 0.8910119061269945\n",
      "Mean cross validation train score: 0.892926061684121\n",
      "Standard deviation in cv test scores: 0.005674787793995626\n"
     ]
    }
   ],
   "source": [
    "# Now crossvalidate again:\n",
    "cv_scores_train= cross_val_score(rf_1,X_train_s,y_train,cv=10,scoring='precision_macro')\n",
    "cv_scores_test= cross_val_score(rf_1,X_test_s,y_test,cv=10,scoring='precision_macro')\n",
    "print(cv_scores_test)\n",
    "cv_scores_RF_test= cv_scores_test.mean()\n",
    "cv_scores_RF_train= cv_scores_train.mean()\n",
    "cv_scores_std_RF= cv_scores_test.std()\n",
    "print ('Mean cross validation test score: ' +str(cv_scores_RF_test))\n",
    "print ('Mean cross validation train score: ' +str(cv_scores_RF_train))\n",
    "print ('Standard deviation in cv test scores: ' +str(cv_scores_std_RF))\n",
    "\n",
    "# We have a very good precition, accuracy and roc_auc using the RF classifier, but the model might be overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aa5b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This shows good prediction on an unseen test set. \n",
    "# Just to make sure I will try with more hyperparameter tuning and see if the moel performence\n",
    "#on the test score is still good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ccd2fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89      6444\n",
      "           1       0.97      0.78      0.86      6405\n",
      "\n",
      "    accuracy                           0.88     12849\n",
      "   macro avg       0.89      0.88      0.88     12849\n",
      "weighted avg       0.89      0.88      0.88     12849\n",
      "\n",
      "[[6310  134]\n",
      " [1437 4968]]\n",
      "0.8774247452743653\n"
     ]
    }
   ],
   "source": [
    "rf_entropy = RandomForestClassifier(bootstrap=True, max_depth=6, criterion='entropy')\n",
    "rf_entropy.fit(X_train_s, y_train)\n",
    "#Predict using the model:\n",
    "y_predict_entropy = rf_entropy.predict(X_test_s)\n",
    "#Confusion matrix:\n",
    "cnf_matrix_1 = confusion_matrix(y_test, y_predict_entropy)\n",
    "ra_1=roc_auc_score(y_test, y_predict_entropy)\n",
    "print(classification_report(y_test, y_predict_entropy))\n",
    "print(cnf_matrix_1)\n",
    "print(ra_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "43f17523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n_estimators: 23\n",
      "Best max_depth: 15\n",
      "Best min_samples_leaf: 8\n"
     ]
    }
   ],
   "source": [
    "n_estimators = list(range(1,50))\n",
    "max_depth = list(range(1,20))\n",
    "min_samples_leaf= list(range(1,10))\n",
    "\n",
    "hyperparameters = dict(n_estimators=n_estimators, max_depth= max_depth, min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "#Use GridSearch\n",
    "clf = RandomizedSearchCV(Rf, hyperparameters, cv=10)\n",
    "best_model = clf.fit(X_train_s, y_train)\n",
    "\n",
    "#Print The value of best Hyperparameters\n",
    "print('Best n_estimators:', best_model.best_estimator_.get_params()['n_estimators'])\n",
    "print('Best max_depth:', best_model.best_estimator_.get_params()['max_depth'])\n",
    "print('Best min_samples_leaf:', best_model.best_estimator_.get_params()['min_samples_leaf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "07720c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90      6444\n",
      "           1       0.96      0.82      0.88      6405\n",
      "\n",
      "    accuracy                           0.89     12849\n",
      "   macro avg       0.90      0.89      0.89     12849\n",
      "weighted avg       0.90      0.89      0.89     12849\n",
      "\n",
      "[[6228  216]\n",
      " [1168 5237]]\n",
      "0.8920614568750846\n"
     ]
    }
   ],
   "source": [
    "# To make sure I will crossvalidate the sample with the best Random Forest model.\n",
    "RF=RandomForestClassifier(max_depth=15, n_estimators=23, min_samples_leaf=8)\n",
    "RF.fit(X_train_s, y_train)\n",
    "y_pred_RF=RF.predict(X_test_s)\n",
    "cnf_matrix_RF = confusion_matrix(y_test, y_pred_RF)\n",
    "ra_RF=roc_auc_score(y_test, y_pred_RF)\n",
    "print(classification_report(y_test, y_pred_RF))\n",
    "print(cnf_matrix_RF)\n",
    "print(ra_RF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
